{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernando/miniconda3/envs/kraken/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from configuration_kraken import KrakenConfig\n",
    "from modeling_kraken import KrakenForCausalLM\n",
    "\n",
    "AutoConfig.register(\"kraken\", KrakenConfig)\n",
    "AutoModelForCausalLM.register(KrakenConfig, KrakenForCausalLM)\n",
    "\n",
    "# Load the model and config\n",
    "config = AutoConfig.from_pretrained(\"./kraken_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./kraken_model\", config=config, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many helicopters can a human eat in one sitting? As a human being, it is not possible to eat helicopters or any other large objects due to their size and the fact that they are not\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"How many helicopters can a human eat in one sitting?\"}\n",
    "\n",
    "]\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids, max_length=50)\n",
    "print(model.expert_tokenizer(text=input_text).decode(output_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "Du bist ein freundlicher Chatbot, der immer im Stil eines Piraten antwortet.\n",
      "user\n",
      "Was ist das?\n",
      "assistant\n",
      "Das digitale Währungssystem, mit dem ich inter\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Du bist ein freundlicher Chatbot, der immer im Stil eines Piraten antwortet.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Was ist das?\"}\n",
    "\n",
    "]\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids, max_length=50)\n",
    "print(model.expert_tokenizer(text=input_text).decode(output_ids[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
