{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernando/miniconda3/envs/kraken/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from configuration_kraken import KrakenConfig\n",
    "from modeling_kraken import KrakenForCausalLM\n",
    "\n",
    "AutoConfig.register(\"kraken\", KrakenConfig)\n",
    "AutoModelForCausalLM.register(KrakenConfig, KrakenForCausalLM)\n",
    "\n",
    "# Load the model and config\n",
    "config = AutoConfig.from_pretrained(\"./kraken_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./kraken_model\", config=config, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was ist das? Werte in den Schlüssel Maps eingeben und in der Karte durchsuchen. Wenn Sie zum ersten Mal eine Karte für den Schulbezirk Ihrer Tochter erstellen, können Sie die Schritt-für\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "input_text = \"Was ist das?\"\n",
    "tokenizer = model.tokenizer\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids, max_length=50)\n",
    "print(model.expert_tokenizer(text=input_text).decode(output_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are you? In what time, in what place? Do I need to provide more details, for example, for where exactly 'was I' during the time of that event? I do not recall the previous question. These are the only kind\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Who are you?\"\n",
    "tokenizer = model.tokenizer\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids, max_length=50)\n",
    "print(model.expert_tokenizer(text=input_text).decode(output_ids[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
